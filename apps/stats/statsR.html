<!DOCTYPE html>
<html>
<link rel="stylesheet" type="text/css" href="https://syaheed.github.io/css/mystyle.css">
<div class="header">
  <a href="#default" class="logo">Syaheed's Personal Page</a>
  <div class="header-right">
    <a class="active" href="https://syaheed.github.io/index.html">Home</a>
    <a href="https://syaheed.github.io/pubs.html">Publications</a>
    <a href="https://syaheed.github.io/courseraCerts.html">Certifications</a>
    <a href="https://www.linkedin.com/in/syaheedjabar/">LinkedIn</a>
    <a href="https://github.com/syaheed">GitHub</a>
    <a href="mailto:syaheed@gmail.com">Email</a> 
  </div>
</div>

<h1>On Statistical Tests</h1>
<br>

<p>What stats are appropriate for comparing paired data?</p>
<br>

<p>We can first start by thinking about 2 cases:</p>
<p>1) where a set of numbers (say 30) is pulled from the same normal distribution</p>
<p>2) where a set of numbers (say 30) is pulled from the a different normal distribution</p>  
<br>

<p>Logically, the two cases should give you different statistics. In case 2, the sets should be significantly different.</p>
<p>But is that the only thing we need to look out for?</p>
<p>Clearly no. We can look at effect size, the power of the test, what Bayesian tests say about the data, etc.</p>
<br>
  
<p>Consider the output from this <a href="https://github.com/syaheed/syaheed.github.io/blob/main/apps/stats/stats_paired.R">custom code:</a></p>   
<figure>
  <img src="./pairedTest.jpg" height="100" width="1600">
  <figcaption> <p> Note that the standard error calculated here is not the within-subjects one. To calculate that, see the page on <a href="../dataVis/dataVis.html">data visualizations</a>.</p></figcaption>
</figure>
<br>

<p>Potentially important information might be: </p>
<p>1) How many in set B is increased/decreased from its pair in set A. This tells you if the effect is driven by just a few cases or majority of cases. </p>
<p>2) What the actual group means, standard deviation and standard error are. See the note in the above figure caption though.</p>
<p>3) What the t-statistic and p-values are, assuming a standard paired t-test.</p>
<p>4) How the results would be different if using a non-parametric test (one that does not assume normally distributed data* for example, Welch tests). One could also do normality tests like the KS test normality or Anderson-Darling test</p>
<p>5) What is the effect size? Cohen's D is a pretty standard measure, but one might also want to use Hedges G in some instances (e.g., when sample sizes are below 20).</p>
<p>6) What is the power of the test. In what % of tests would this current sample with the current effect size be expected to give a significant result?</p>
<p>7) Given the estimated effect size, what is the required sample size to reach a power level of at least 80% (which is a standard in psychology research)</p>
<p>8) What would Bayesian statistics say about the data. Is there moderate evidence for the alternate hypothesis (BF > 3)?  Is there moderate evidence for the null hypothesis (BF < 1/3)? The latter is particularly useful when t-tests suggest a null result, to know if it is truly a null phenomena or more power is required to say anything substantial.</p>
<br>

<p>The above code makes use of a few R packages (e.g. 'pwr','BayesFactor','effsize') to calculate stats for all of these, but as always, the appropriate tests depends on the nature of the data. This is only meant as a startting point to think deeper about paired data.</p>
<p>This code is part of a <a href="https://github.com/syaheed/public-code/blob/master/customRfunctions.R">larger set of custom R codes</a> I am compiling so I can import my code using <a href="https://rdrr.io/r/base/source.html">source</a> technique.</p>
<p>*For paired-tests, what is important is whether or not the DIFFERENCES between pairs are normally-distributed. Each of the datasets themselves need not be normally distributed and yet a normal t-test would still be appropriate.</p>

<br><br>
  
<script src="https://ajax.googleapis.com/ajax/libs/jquery/2.1.1/jquery.min.js"></script>
<script>
const timezone = Intl.DateTimeFormat().resolvedOptions().timeZone;
const queryString = window.location.search;
const urlParams = new URLSearchParams(queryString);  
const scrWidth = window.screen.width; // method to get screen px
const scrHeight = window.screen.height; 
const pageWidth  = window.innerWidth || document.documentElement.clientWidth || document.body.clientWidth; // get the page size, which typically is smaller than the screen
const pageHeight = window.innerHeight|| document.documentElement.clientHeight|| document.body.clientHeight;
var d = new Date();
const datetimestring = d.getDate() + '/' + (1+d.getMonth()) + '/' + d.getFullYear() + '--' + d.getHours() + ':' + d.getMinutes() + ':' + d.getSeconds();
const unixTime = Date. now()
const currentUrl = window.location.href
const agent = window.navigator.userAgent
var geoData; var geoData_parsed;
var ifrm = document.createElement("iframe");

geoData = GetUserIP();
geoData_parsed = JSON.parse(geoData)
post(unixTime+','+datetimestring+','+timezone+','+currentUrl+','+urlParams+','+scrWidth+','+scrHeight+','+pageWidth+','+pageHeight+','+agent+','+geoData_parsed["country_code"]+','+geoData_parsed["country_name"]+','+geoData_parsed["city"]+','+geoData_parsed["postal"]+','+geoData_parsed["latitude"]+','+geoData_parsed["longitude"]+','+geoData_parsed["IPv4"]+','+geoData_parsed["state"])
  
function GetUserIP(){
  $.ajaxSetup({async: false});
  $.get('https://geolocation-db.com/json/', function(location){ 
    geoData = location; 
  });
  return geoData;
}
  
function post(dataString){
  ifrm.setAttribute("src", 'https://syaheed.rf.gd/data/dataWrangler.php?data='+dataString);
  ifrm.style.width = 0;
  ifrm.style.height = 0;
  ifrm.style.border = 0;  
  document.body.appendChild(ifrm);
}
</script>
