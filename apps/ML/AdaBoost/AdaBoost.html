<!DOCTYPE html>
<html>
<link rel="stylesheet" type="text/css" href="https://syaheed.github.io/css/mystyle.css">
<div class="header">
  <a href="#default" class="logo">Syaheed's Personal Page</a>
  <div class="header-right">
    <a class="active" href="https://syaheed.github.io/index.html">Home</a>
    <a href="https://syaheed.github.io/pubs.html">Publications</a>
    <a href="https://syaheed.github.io/courseraCerts.html">Certifications</a>
    <a href="https://www.linkedin.com/in/syaheedjabar/">LinkedIn</a>
    <a href="https://github.com/syaheed">GitHub</a>
    <a href="mailto:syaheed@gmail.com">Email</a> 
  </div>
</div>

<h1>How many estimators does AdaBoost need for a proper regression?</h1>

<p><a href="https://scikit-learn.org/stable/auto_examples/ensemble/plot_adaboost_regression.html#sphx-glr-auto-examples-ensemble-plot-adaboost-regression-p">The sciki-learn website</a> has an example of how AdaBoost affects the estimate over a decision tree, for a sinusoidal function. The example uses 300 estimators, but is that enough? How much is enough?</p><br>
<p>Really, what we want to know is how the fit changes as the number of boosts increases. For that, let's take a look at the loss function across number of boosts (green line is the base decision tree model, red line uses 600 estimators/boosts): </p>

<figure>
  <img src="./AdaBoost.png" height="800" width="1100">
</figure>

<br><p>For this case, looks like the indicated 300 boosts is sufficient. The loss (sum of square errors) function flattens out before that.</p>
<br><p>Clearly boosting the decision tree has a beneficial effect on the fit of the model, but it also is not perfectly predicting the sinusoidal pattern</p>  
<br><p><a href="https://github.com/syaheed/syaheed.github.io/blob/main/apps/ML/AdaBoost/AdaBoost.py">Python/Scikit-Learn code</a> used (modified from the official example).</p>
